{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepachandran-S/PATIENT-READMISSION/blob/main/DEPLOYED_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjIvKsdg4H0Z",
        "outputId": "15ac32fd-4c69-4f8b-e9e7-0eafc166cc78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "encounter_id                float64\n",
              "patient_nbr                 float64\n",
              "race                         object\n",
              "gender                       object\n",
              "age                          object\n",
              "admission_type_id           float64\n",
              "discharge_disposition_id    float64\n",
              "admission_source_id         float64\n",
              "time_in_hospital            float64\n",
              "medical_specialty            object\n",
              "num_lab_procedures          float64\n",
              "num_procedures              float64\n",
              "num_medications             float64\n",
              "number_outpatient           float64\n",
              "number_emergency            float64\n",
              "number_inpatient            float64\n",
              "diag_1                       object\n",
              "diag_2                       object\n",
              "diag_3                       object\n",
              "number_diagnoses            float64\n",
              "max_glu_serum                object\n",
              "A1Cresult                    object\n",
              "metformin                    object\n",
              "repaglinide                  object\n",
              "nateglinide                  object\n",
              "chlorpropamide               object\n",
              "glimepiride                  object\n",
              "acetohexamide                object\n",
              "glipizide                    object\n",
              "glyburide                    object\n",
              "tolbutamide                  object\n",
              "pioglitazone                 object\n",
              "rosiglitazone                object\n",
              "acarbose                     object\n",
              "miglitol                     object\n",
              "troglitazone                 object\n",
              "tolazamide                   object\n",
              "examide                      object\n",
              "citoglipton                  object\n",
              "insulin                      object\n",
              "glyburide-metformin          object\n",
              "glipizide-metformin          object\n",
              "glimepiride-pioglitazone     object\n",
              "metformin-rosiglitazone      object\n",
              "metformin-pioglitazone       object\n",
              "change                       object\n",
              "diabetesMed                  object\n",
              "readmitted                    int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zodRRH5Ggg4C",
        "outputId": "0f5643ad-974f-45b4-fe27-2f39f01f8c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2202/2202 [==============================] - 4s 2ms/step\n",
            "Prediction: 0.0\n"
          ]
        }
      ],
      "source": [
        "'''import warnings\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Suppress future warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Define the preprocessing function\n",
        "def preprocess_data(df):\n",
        "    # Encode missing values as NaN\n",
        "    df.replace('?', np.nan, inplace=True)\n",
        "\n",
        "    # Drop columns with more than 50% missing values\n",
        "    df.drop(['weight', 'payer_code'], axis=1, inplace=True)\n",
        "\n",
        "    # Fill missing values with a new category 'Missing' for 'medical_specialty'\n",
        "    df['medical_specialty'].fillna('Missing', inplace=True)\n",
        "\n",
        "    # Fill missing values for numeric columns with mean and for categorical columns with mode\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    categorical_cols = df.select_dtypes(include=[object]).columns\n",
        "\n",
        "    numeric_imputer = SimpleImputer(strategy='mean')\n",
        "    df[numeric_cols] = numeric_imputer.fit_transform(df[numeric_cols])\n",
        "\n",
        "    categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "    df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
        "\n",
        "    # Encode 'readmitted' to binary classes\n",
        "    df['readmitted'] = df['readmitted'].replace({'<30': 1, '>30': 1, 'NO': 0})\n",
        "\n",
        "    # Drop patients with expired discharge disposition or discharged to hospice\n",
        "    df = df[~df['discharge_disposition_id'].isin([11, 19, 20, 21])]\n",
        "\n",
        "    # Keep only the first encounter for each patient\n",
        "    df = df.sort_values(by=['patient_nbr', 'encounter_id']).drop_duplicates(subset=['patient_nbr'], keep='first')\n",
        "\n",
        "    # Encode 'age' as discrete\n",
        "    age_dict = {'[0-10)': 5, '[10-20)': 15, '[20-30)': 25, '[30-40)': 35, '[40-50)': 45, '[50-60)': 55,\n",
        "                '[60-70)': 65, '[70-80)': 75, '[80-90)': 85, '[90-100)': 95}\n",
        "    df['age'] = df['age'].map(age_dict)\n",
        "\n",
        "    # Clustering diagnosis codes into 9 categories\n",
        "    def cluster_diag(diag):\n",
        "        if diag.startswith('250'):\n",
        "            return 'Diabetes'\n",
        "        elif diag.startswith('390') or diag.startswith('459') or diag.startswith('785'):\n",
        "            return 'Circulatory'\n",
        "        elif diag.startswith('460') or diag.startswith('519') or diag.startswith('786'):\n",
        "            return 'Respiratory'\n",
        "        elif diag.startswith('520') or diag.startswith('579') or diag.startswith('787'):\n",
        "            return 'Digestive'\n",
        "        elif diag.startswith('800') or diag.startswith('999'):\n",
        "            return 'Injury'\n",
        "        elif diag.startswith('710') or diag.startswith('739'):\n",
        "            return 'Musculoskeletal'\n",
        "        elif diag.startswith('580') or diag.startswith('629'):\n",
        "            return 'Genitourinary'\n",
        "        elif diag.startswith('140') or diag.startswith('239'):\n",
        "            return 'Neoplasms'\n",
        "        else:\n",
        "            return 'Other'\n",
        "\n",
        "    df['diag_1'] = df['diag_1'].apply(cluster_diag)\n",
        "    df['diag_2'] = df['diag_2'].apply(cluster_diag)\n",
        "    df['diag_3'] = df['diag_3'].apply(cluster_diag)\n",
        "\n",
        "    # Clustering 'medical_specialty' and other variables\n",
        "    df['medical_specialty'] = df['medical_specialty'].apply(lambda x: 'Surgery' if 'Surgery' in x else x)\n",
        "\n",
        "    # Encoding categorical variables\n",
        "    label_encoders = {}\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "        label_encoders[col] = le\n",
        "\n",
        "    # Feature engineering\n",
        "    df['service_utilization'] = df['number_outpatient'] + df['number_emergency'] + df['number_inpatient']\n",
        "    df['count_medication_change'] = df[['change']].apply(lambda x: x.count(), axis=1)\n",
        "    df['count_medication_used'] = df[['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
        "                                      'glimepiride', 'acetohexamide', 'glipizide', 'glyburide',\n",
        "                                      'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose',\n",
        "                                      'miglitol', 'troglitazone', 'tolazamide', 'examide',\n",
        "                                      'citoglipton', 'insulin', 'glyburide-metformin',\n",
        "                                      'glipizide-metformin', 'glimepiride-pioglitazone',\n",
        "                                      'metformin-rosiglitazone', 'metformin-pioglitazone']].apply(lambda x: (x != 'No').sum(), axis=1)\n",
        "\n",
        "    # Drop columns with uniform values\n",
        "    df.drop(['examide', 'citoglipton'], axis=1, inplace=True)\n",
        "\n",
        "    # Log transformation for skewed numeric columns\n",
        "    skewed_cols = ['num_lab_procedures', 'num_procedures', 'num_medications', 'number_diagnoses']\n",
        "    df[skewed_cols] = df[skewed_cols].apply(lambda x: np.log1p(x))\n",
        "\n",
        "    # Standardize numeric columns\n",
        "    scaler = StandardScaler()\n",
        "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "    r=df['readmitted']\n",
        "    df.drop('readmitted',axis=1,inplace=True)\n",
        "    df=df[['race', 'gender', 'age',\n",
        "       'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
        "       'time_in_hospital', 'medical_specialty', 'num_lab_procedures',\n",
        "       'num_procedures', 'num_medications', 'number_outpatient',\n",
        "       'number_inpatient', 'number_diagnoses', 'A1Cresult', 'metformin',\n",
        "       'glipizide', 'glyburide', 'pioglitazone', 'insulin', 'change',\n",
        "       'diabetesMed', 'service_utilization','diag_1','diag_2']]\n",
        "    return df\n",
        "# Example usage\n",
        "df = pd.read_csv('/content/drive/MyDrive/CODIIS/diabetic_data.csv')\n",
        "\n",
        "preprocessed_data = preprocess_data(df)\n",
        "\n",
        "# Ensure the data is in the correct shape\n",
        "#preprocessed_data = preprocessed_data.to_numpy()\n",
        "\n",
        "\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(preprocessed_data)\n",
        "print(f'Prediction: {prediction[0][].round()}')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3zsbYs3gGDS",
        "outputId": "0ad4f82e-80de-4920-f008-ef1a60755602"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urOS5TLFftfV"
      },
      "outputs": [],
      "source": [
        "'''import warnings\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Suppress future warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Define the preprocessing function\n",
        "def preprocess_data(df):\n",
        "    # Encode missing values as NaN\n",
        "    df.replace('?', np.nan, inplace=True)\n",
        "\n",
        "    # Drop columns with more than 50% missing values\n",
        "    df.drop(['weight', 'payer_code'], axis=1, inplace=True)\n",
        "\n",
        "    # Fill missing values with a new category 'Missing' for 'medical_specialty'\n",
        "    df['medical_specialty'].fillna('Missing', inplace=True)\n",
        "\n",
        "    # Fill missing values for numeric columns with mean and for categorical columns with mode\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    categorical_cols = df.select_dtypes(include=[object]).columns\n",
        "\n",
        "    numeric_imputer = SimpleImputer(strategy='mean')\n",
        "    df[numeric_cols] = numeric_imputer.fit_transform(df[numeric_cols])\n",
        "\n",
        "    categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "    df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
        "\n",
        "    # Encode 'readmitted' to binary classes\n",
        "    df['readmitted'] = df['readmitted'].replace({'<30': 1, '>30': 1, 'NO': 0})\n",
        "\n",
        "    # Drop patients with expired discharge disposition or discharged to hospice\n",
        "    df = df[~df['discharge_disposition_id'].isin([11, 19, 20, 21])]\n",
        "\n",
        "    # Keep only the first encounter for each patient\n",
        "    df = df.sort_values(by=['patient_nbr', 'encounter_id']).drop_duplicates(subset=['patient_nbr'], keep='first')\n",
        "\n",
        "    # Encode 'age' as discrete\n",
        "    age_dict = {'[0-10)': 5, '[10-20)': 15, '[20-30)': 25, '[30-40)': 35, '[40-50)': 45, '[50-60)': 55,\n",
        "                '[60-70)': 65, '[70-80)': 75, '[80-90)': 85, '[90-100)': 95}\n",
        "    df['age'] = df['age'].map(age_dict)\n",
        "\n",
        "    # Clustering diagnosis codes into 9 categories\n",
        "    def cluster_diag(diag):\n",
        "        if diag.startswith('250'):\n",
        "            return 'Diabetes'\n",
        "        elif diag.startswith('390') or diag.startswith('459') or diag.startswith('785'):\n",
        "            return 'Circulatory'\n",
        "        elif diag.startswith('460') or diag.startswith('519') or diag.startswith('786'):\n",
        "            return 'Respiratory'\n",
        "        elif diag.startswith('520') or diag.startswith('579') or diag.startswith('787'):\n",
        "            return 'Digestive'\n",
        "        elif diag.startswith('800') or diag.startswith('999'):\n",
        "            return 'Injury'\n",
        "        elif diag.startswith('710') or diag.startswith('739'):\n",
        "            return 'Musculoskeletal'\n",
        "        elif diag.startswith('580') or diag.startswith('629'):\n",
        "            return 'Genitourinary'\n",
        "        elif diag.startswith('140') or diag.startswith('239'):\n",
        "            return 'Neoplasms'\n",
        "        else:\n",
        "            return 'Other'\n",
        "\n",
        "    df['diag_1'] = df['diag_1'].apply(cluster_diag)\n",
        "    df['diag_2'] = df['diag_2'].apply(cluster_diag)\n",
        "    df['diag_3'] = df['diag_3'].apply(cluster_diag)\n",
        "\n",
        "    # Clustering 'medical_specialty' and other variables\n",
        "    df['medical_specialty'] = df['medical_specialty'].apply(lambda x: 'Surgery' if 'Surgery' in x else x)\n",
        "\n",
        "    # Encoding categorical variables\n",
        "    label_encoders = {}\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "        label_encoders[col] = le\n",
        "\n",
        "    # Feature engineering\n",
        "    df['service_utilization'] = df['number_outpatient'] + df['number_emergency'] + df['number_inpatient']\n",
        "    df['count_medication_change'] = df[['change']].apply(lambda x: x.count(), axis=1)\n",
        "    df['count_medication_used'] = df[['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
        "                                      'glimepiride', 'acetohexamide', 'glipizide', 'glyburide',\n",
        "                                      'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose',\n",
        "                                      'miglitol', 'troglitazone', 'tolazamide', 'examide',\n",
        "                                      'citoglipton', 'insulin', 'glyburide-metformin',\n",
        "                                      'glipizide-metformin', 'glimepiride-pioglitazone',\n",
        "                                      'metformin-rosiglitazone', 'metformin-pioglitazone']].apply(lambda x: (x != 'No').sum(), axis=1)\n",
        "\n",
        "    # Drop columns with uniform values\n",
        "    df.drop(['examide', 'citoglipton'], axis=1, inplace=True)\n",
        "\n",
        "    # Log transformation for skewed numeric columns\n",
        "    skewed_cols = ['num_lab_procedures', 'num_procedures', 'num_medications', 'number_diagnoses']\n",
        "    df[skewed_cols] = df[skewed_cols].apply(lambda x: np.log1p(x))\n",
        "\n",
        "    # Standardize numeric columns\n",
        "    scaler = StandardScaler()\n",
        "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "    r=df['readmitted']\n",
        "    df.drop('readmitted',axis=1,inplace=True)\n",
        "    df=df[['race', 'gender', 'age',\n",
        "       'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
        "       'time_in_hospital', 'medical_specialty', 'num_lab_procedures',\n",
        "       'num_procedures', 'num_medications', 'number_outpatient',\n",
        "       'number_inpatient', 'number_diagnoses', 'A1Cresult', 'metformin',\n",
        "       'glipizide', 'glyburide', 'pioglitazone', 'insulin', 'change',\n",
        "       'diabetesMed', 'service_utilization']]\n",
        "    return df,r\n",
        "df = pd.read_csv('/content/drive/MyDrive/CODIIS/diabetic_data.csv')\n",
        "preprocessed_data = preprocess_data(df)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXF3GBiRgwlb",
        "outputId": "d8f4c3f2-9757-4a02-936e-9718832ab983"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4267      1\n",
              "5827      0\n",
              "67608     0\n",
              "17494     0\n",
              "2270      0\n",
              "         ..\n",
              "99863     0\n",
              "95282     0\n",
              "93651     0\n",
              "101748    1\n",
              "96147     0\n",
              "Name: readmitted, Length: 70439, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2=preprocessed_data\n",
        "df2[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylV9pyJliplu",
        "outputId": "87799d55-c1b3-4a00-d524-da995bb584a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 22760, number of negative: 33591\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011840 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 432\n",
            "[LightGBM] [Info] Number of data points in the train set: 56351, number of used features: 23\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "0.6142816581487791\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create a sample dataset (replace this with your actual data)\n",
        "#X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df2[0],df2[1], test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a LightGBM classifier\n",
        "lgb_estimator = lgb.LGBMClassifier(class_weight='balanced')\n",
        "\n",
        "\n",
        "# Fit the RFE model\n",
        "lgb_estimator.fit(X_train, y_train)\n",
        "\n",
        "# Transform the training and testing sets based on the selected features\n",
        "\n",
        "\n",
        "# Fit the LightGBM model on the selected features\n",
        "#lgb_estimator.fit(X_train_rfe, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = lgb_estimator.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred.round())\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCdDGlhek4-c",
        "outputId": "ae63b5b4-019c-4801-c3dd-a6e3b1bbbe3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 22760, number of negative: 33591\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012551 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 432\n",
            "[LightGBM] [Info] Number of data points in the train set: 56351, number of used features: 23\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 22760, number of negative: 33591\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011812 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 432\n",
            "[LightGBM] [Info] Number of data points in the train set: 56351, number of used features: 23\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "Accuracy: 0.6124361158432708\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "\n",
        "# Load your dataset\n",
        "# df = pd.read_csv('your_dataset.csv')  # Assuming your dataset is already loaded\n",
        "\n",
        "  # Assuming 'target' is the column name for the target variable\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df2[0],df2[1], test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the LightGBM classifier\n",
        "lgb_clf = lgb.LGBMClassifier(class_weight='balanced')\n",
        "\n",
        "# Define hyperparameters for tuning\n",
        "param_grid = {\n",
        "    'num_leaves': [31, 50],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'n_estimators': [100, 200]\n",
        "}\n",
        "\n",
        "# Perform hyperparameter tuning with GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=lgb_clf, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best estimator\n",
        "best_clf = grid_search.best_estimator_\n",
        "\n",
        "# Train the model with the best estimator\n",
        "best_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = best_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Save the model\n",
        "with open('lgb_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_clf, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPSRLI2HldX_",
        "outputId": "e47ec42d-e49b-44e9-b6fe-ed05a0d1971e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[5093, 3217],\n",
              "       [2243, 3535]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test,y_pred.round())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uJhskACpubz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c618a8f6-a273-4024-c163-c863cfde2248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-8b45d3744b5e>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['medical_specialty'].fillna('Missing', inplace=True)\n",
            "<ipython-input-2-8b45d3744b5e>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[numeric_cols] = numeric_imputer.fit_transform(df[numeric_cols])\n",
            "<ipython-input-2-8b45d3744b5e>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
            "<ipython-input-2-8b45d3744b5e>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['age'] = df['age'].map(age_dict)\n",
            "<ipython-input-2-8b45d3744b5e>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = le.fit_transform(df[col])\n",
            "<ipython-input-2-8b45d3744b5e>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = le.fit_transform(df[col])\n",
            "<ipython-input-2-8b45d3744b5e>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = le.fit_transform(df[col])\n",
            "<ipython-input-2-8b45d3744b5e>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = le.fit_transform(df[col])\n",
            "<ipython-input-2-8b45d3744b5e>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = le.fit_transform(df[col])\n",
            "<ipython-input-2-8b45d3744b5e>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = le.fit_transform(df[col])\n",
            "<ipython-input-2-8b45d3744b5e>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = le.fit_transform(df[col])\n",
            "<ipython-input-2-8b45d3744b5e>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = le.fit_transform(df[col])\n",
            "<ipython-input-2-8b45d3744b5e>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = le.fit_transform(df[col])\n",
            "<ipython-input-2-8b45d3744b5e>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = le.fit_transform(df[col])\n",
            "<ipython-input-2-8b45d3744b5e>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = le.fit_transform(df[col])\n",
            "<ipython-input-2-8b45d3744b5e>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = le.fit_transform(df[col])\n",
            "<ipython-input-2-8b45d3744b5e>:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_and_save_encoders(df):\n",
        "    # Encode missing values as NaN\n",
        "    df.replace('?', np.nan, inplace=True)\n",
        "\n",
        "    # Columns to preprocess\n",
        "    columns_to_keep = ['race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id',\n",
        "                       'admission_source_id', 'time_in_hospital', 'medical_specialty',\n",
        "                       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
        "                       'number_outpatient', 'number_inpatient', 'number_diagnoses',\n",
        "                       'A1Cresult', 'metformin', 'glipizide', 'glyburide',\n",
        "                       'pioglitazone', 'insulin', 'change', 'diabetesMed']\n",
        "    df = df[columns_to_keep]\n",
        "\n",
        "    # Fill missing values\n",
        "    df['medical_specialty'].fillna('Missing', inplace=True)\n",
        "\n",
        "    # Fill missing values for numeric columns with mean and for categorical columns with mode\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    categorical_cols = df.select_dtypes(include=[object]).columns\n",
        "\n",
        "    numeric_imputer = SimpleImputer(strategy='mean')\n",
        "    df[numeric_cols] = numeric_imputer.fit_transform(df[numeric_cols])\n",
        "\n",
        "    categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "    df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
        "\n",
        "    # Encode 'age' as discrete\n",
        "    age_dict = {'[0-10)': 5, '[10-20)': 15, '[20-30)': 25, '[30-40)': 35, '[40-50)': 45, '[50-60)': 55,\n",
        "                '[60-70)': 65, '[70-80)': 75, '[80-90)': 85, '[90-100)': 95}\n",
        "    df['age'] = df['age'].map(age_dict)\n",
        "\n",
        "    # Encoding categorical variables\n",
        "    label_encoders = {}\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "        label_encoders[col] = le\n",
        "\n",
        "    # Standardize numeric columns\n",
        "    scaler = StandardScaler()\n",
        "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "\n",
        "    # Save the label encoders and the scaler\n",
        "    with open('label_encoders.pkl', 'wb') as file:\n",
        "        pickle.dump(label_encoders, file)\n",
        "\n",
        "    with open('scaler.pkl', 'wb') as file:\n",
        "        pickle.dump(scaler, file)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage\n",
        "#df = pd.read_csv('/content/drive/MyDrive/CODIIS/diabetic_data.csv')\n",
        "#df_preprocessed = preprocess_and_save_encoders(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF43a5rthDHJ",
        "outputId": "54194a53-e665-41d8-b006-6b5dcf15125a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.36.0-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.36.0 watchdog-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rlgKwORnVQo",
        "outputId": "6d5b9464-b890-451a-fbd2-54f87b12cdae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app5.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app5.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load the saved model, label encoders, and scaler\n",
        "with open('lgb_model.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "with open('label_encoders2.pkl', 'rb') as file:\n",
        "    label_encoders = pickle.load(file)\n",
        "#with open('scaler.pkl', 'rb') as file:\n",
        "    #scaler = pickle.load(file)\n",
        "\n",
        "# Define the preprocessing function for new input\n",
        "def preprocess_input(input_df):\n",
        "    # Encode 'age' as discrete\n",
        "    age_dict = {'[0-10)': 5, '[10-20)': 15, '[20-30)': 25, '[30-40)': 35, '[40-50)': 45, '[50-60)': 55,\n",
        "                '[60-70)': 65, '[70-80)': 75, '[80-90)': 85, '[90-100)': 95}\n",
        "    input_df['age'] = input_df['age'].map(age_dict)\n",
        "    input_df['A1Cresult']=input_df['A1Cresult'].replace({'None':0, 'Norm':1, '>7':2, '>8':3})\n",
        "    # Encoding categorical variables\n",
        "    for col in label_encoders:\n",
        "      try:\n",
        "        input_df[col] = label_encoders[col].transform(input_df[col])\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "\n",
        "    # Standardize numeric columns\n",
        "    numeric_cols = input_df.select_dtypes(include=[np.number]).columns\n",
        "    input_df[numeric_cols] = StandardScaler().fit_transform(input_df[numeric_cols])\n",
        "\n",
        "    return input_df\n",
        "\n",
        "# Define the Streamlit app\n",
        "st.title('Medical Readmission Prediction')\n",
        "\n",
        "# Define input fields\n",
        "race = st.selectbox('Race', ['Caucasian', 'AfricanAmerican', 'Other', 'Asian', 'Hispanic'])\n",
        "gender = st.selectbox('Gender', ['Male', 'Female'])\n",
        "age = st.selectbox('Age', ['[0-10)', '[10-20)', '[20-30)', '[30-40)', '[40-50)', '[50-60)', '[60-70)', '[70-80)', '[80-90)', '[90-100)'])\n",
        "admission_type_id = st.selectbox('Admission Type ID', [1, 2, 3, 4, 5, 6, 7, 8])\n",
        "discharge_disposition_id = st.selectbox('Discharge Disposition ID', [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30])\n",
        "admission_source_id = st.selectbox('Admission Source ID', [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 20, 21, 22, 25, 26])\n",
        "time_in_hospital = st.number_input('Time in Hospital', min_value=1, max_value=14, value=1)\n",
        "medical_specialty = st.selectbox('Medical Specialty', ['Cardiology', 'Endocrinology', 'Family/GeneralPractice', 'InternalMedicine', 'Nephrology', 'Neurology', 'ObstetricsandGynecology', 'Oncology', 'Orthopedics', 'Pediatrics', 'Pulmonology', 'Radiology', 'Surgery-General', 'Urology', 'Other'])\n",
        "num_lab_procedures = st.number_input('Number of Lab Procedures', min_value=0, max_value=132, value=0)\n",
        "num_procedures = st.number_input('Number of Procedures', min_value=0, max_value=6, value=0)\n",
        "num_medications = st.number_input('Number of Medications', min_value=1, max_value=81, value=1)\n",
        "number_outpatient = st.number_input('Number of Outpatient Visits', min_value=0, max_value=42, value=0)\n",
        "number_inpatient = st.number_input('Number of Inpatient Visits', min_value=0, max_value=21, value=0)\n",
        "number_diagnoses = st.number_input('Number of Diagnoses', min_value=1, max_value=16, value=1)\n",
        "A1Cresult = st.selectbox('A1C Result', ['None', 'Norm', '>7', '>8'])\n",
        "metformin = st.selectbox('Metformin', ['No', 'Steady', 'Up', 'Down'])\n",
        "glipizide = st.selectbox('Glipizide', ['No', 'Steady', 'Up', 'Down'])\n",
        "glyburide = st.selectbox('Glyburide', ['No', 'Steady', 'Up', 'Down'])\n",
        "pioglitazone = st.selectbox('Pioglitazone', ['No', 'Steady', 'Up', 'Down'])\n",
        "insulin = st.selectbox('Insulin', ['No', 'Steady', 'Up', 'Down'])\n",
        "change = st.selectbox('Change', ['No', 'Ch'])\n",
        "diabetesMed = st.selectbox('Diabetes Medication', ['No', 'Yes'])\n",
        "\n",
        "# Create a dictionary for the input features\n",
        "input_data = {\n",
        "    'race': race,\n",
        "    'gender': gender,\n",
        "    'age': age,\n",
        "    'admission_type_id': admission_type_id,\n",
        "    'discharge_disposition_id': discharge_disposition_id,\n",
        "    'admission_source_id': admission_source_id,\n",
        "    'time_in_hospital': time_in_hospital,\n",
        "    'medical_specialty': medical_specialty,\n",
        "    'num_lab_procedures': num_lab_procedures,\n",
        "    'num_procedures': num_procedures,\n",
        "    'num_medications': num_medications,\n",
        "    'number_outpatient': number_outpatient,\n",
        "    'number_inpatient': number_inpatient,\n",
        "    'number_diagnoses': number_diagnoses,\n",
        "    'A1Cresult': A1Cresult,\n",
        "    'metformin': metformin,\n",
        "    'glipizide': glipizide,\n",
        "    'glyburide': glyburide,\n",
        "    'pioglitazone': pioglitazone,\n",
        "    'insulin': insulin,\n",
        "    'change': change,\n",
        "    'diabetesMed': diabetesMed,\n",
        "    'service_utilization': number_outpatient + number_inpatient\n",
        "}\n",
        "\n",
        "# Convert the input data to a DataFrame\n",
        "input_df = pd.DataFrame([input_data])\n",
        "\n",
        "# Preprocess the input data\n",
        "input_df = preprocess_input(input_df)\n",
        "\n",
        "# Make a prediction\n",
        "if st.button('Predict'):\n",
        "    prediction = model.predict(input_df)\n",
        "    prediction_proba = model.predict_proba(input_df)\n",
        "\n",
        "    # Display the result\n",
        "    st.write('Prediction: ', 'Readmitted' if prediction[0].round() == 1 else 'Not Readmitted')\n",
        "    st.write('PREDICTION PROBABLITY ')\n",
        "    st.write('NO: ',prediction_proba[0][0])\n",
        "    st.write('YES: ',prediction_proba[0][1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-a58fdsoa3H",
        "outputId": "9271cc0b-2746-47b5-aa0e-38e832327bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.85.185.60"
          ]
        }
      ],
      "source": [
        "!wget -q -O - https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5G-o5DglxIo",
        "outputId": "ec2e39b5-084e-4f85-f00b-f98a17cbbc2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.85.185.60\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.85.185.60:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.886s\n",
            "your url is: https://yummy-spoons-look.loca.lt\n",
            "/root/.npm/_npx/3416/lib/node_modules/localtunnel/bin/lt.js:81\n",
            "    throw err;\n",
            "    ^\n",
            "\n",
            "Error: connection refused: localtunnel.me:35533 (check your firewall settings)\n",
            "    at Socket.<anonymous> (/root/.npm/_npx/3416/lib/node_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11)\n",
            "\u001b[90m    at Socket.emit (events.js:315:20)\u001b[39m\n",
            "\u001b[90m    at emitErrorNT (internal/streams/destroy.js:106:8)\u001b[39m\n",
            "\u001b[90m    at emitErrorCloseNT (internal/streams/destroy.js:74:3)\u001b[39m\n",
            "\u001b[90m    at processTicksAndRejections (internal/process/task_queues.js:80:21)\u001b[39m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app5.py & npx localtunnel --port 8501 & curl ipv4.icanhazip.com\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7apG27ejoGyD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1pw_Qun49Ougz5oVTm-0H_zWZqgyH3hBk",
      "authorship_tag": "ABX9TyP+VwpJ0W4H7l3YT28itXBN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}